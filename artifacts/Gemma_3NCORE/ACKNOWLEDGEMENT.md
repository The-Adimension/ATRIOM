# **ACKNOWLEDGEMENTS**

> To A. Khalifa, A. Elzieny, L. Timmen, M. Ismail, I. Kristanovic-Grigic, A. Breitenstein, Chris Gräni, Isaac Shiri, H. William, H. Raehlmann, H. Hosny, S. Kotit, R. Arroyo-Casado, A. Gimelli, S. E. Petersen, and J. Grapsa - **Thanks for being role models to the Adimension.**


**Gemma 3NCORE and ATRIOM Collections** are made possible through the power of open-source datasets, models, and frameworks. The Adimension gratefully acknowledge the following contributors and providers for their resources, which are used strictly for non-commercial research purposes in alignment with their respective terms of use:
- **Datasets**: Stanford University School of Medicine for the EchoNet-Dynamic Dataset; CREATIS lab (INSA-Lyon, France) for the CAMUS Dataset.
- **Models**: Google DeepMind for the Gemma 3n and MedGemma model families, hosted on Hugging Face; Google for the Health AI Developer Foundations (HAI-DEF).
- **Libraries/Frameworks**: Hugging Face for Transformers, PEFT, Accelerate, and bitsandbytes; PyTorch Team for PyTorch and torchvision; timm contributors for PyTorch Image Models; and all other open-source libraries (numpy, pandas, opencv-python, Pillow, tqdm, matplotlib, seaborn, scikit-learn, unsloth) used in this work.
- **Platforms**: Hugging Face Hub for model hosting and access; Google Colab for computational resources; Kaggle for hosting the Gemma 3n Impact Challenge.

All components comply with ethical guidelines under the DEITY Principles Framework, emphasizing responsible AI development in healthcare.

----
#### **Connect**: Shehab Anwer @  [e-mail 1](mailto:shehab.anwer@gmail.com) | [e-mail 2](mailto:shehab@anwer.ch) | Connect: [X @ShehabAnwer](https://x.com/ShehabAnwer) | [LinkedIn](https://www.linkedin.com/in/shehab-anwer-md) | [GitHub Hab Anwer](https://github.com/HABANWER) | [GitHub The Adimension](https://github.com/The-Adimension)

----
###### LAST UPDATED ON **11 AUGUST 2025**
---

### **References**
1. Gemma Team. (2025). Gemma 3n. Google DeepMind. https://ai.google.dev/gemma/docs/gemma-3n.
2. Anwer, S. (2025). The Adimension: Bridging interoperability through DEITY Principles. *European Heart Journal - Imaging Methods and Practice*. https://doi.org/10.1093/ehjimp/qyaf038.
3. Sellergren, A., et al. (2025). MedGemma Technical Report. arXiv:2507.05201.
4. Wightman, R. (2019). PyTorch Image Models. https://github.com/huggingface/pytorch-image-models.
5. Devvrit et al. (2023). MatFormer: Nested Transformer for Elastic Inference. arXiv:2310.07707.
6. Ouyang, D., et al. (2020). Video-based AI for beat-to-beat assessment of cardiac function. *Nature*. https://doi.org/10.1038/s41586-020-2145-8 (EchoNet-Dynamic Dataset).
7. Leclerc, S., et al. (2019). Deep Learning for Segmentation using an Open Large-Scale Dataset in 2D Echocardiography. *IEEE Transactions on Medical Imaging*. https://doi.org/10.1109/TMI.2019.2900516 (CAMUS Dataset).
8. Hu, E. J., et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models. arXiv:2106.09685.
9. Dettmers, T., et al. (2022). LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale. arXiv:2208.07339.
10. Paszke, A., et al. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. *NeurIPS*.
11. Wolf, T., et al. (2019). Hugging Face's Transformers. arXiv:1910.03771.
12. Google Health AI Team. (2024). Health AI Developer Foundations. arXiv:2411.15128.

##### To **AïA** | Shehab Anwer © [The Adimension](https://theadimension.ch/Introduction.html) 2025.
------